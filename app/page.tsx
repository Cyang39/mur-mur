'use client'

import { useState, useEffect, useRef } from "react";
import { invoke } from "@tauri-apps/api/core";
import { Button } from '@/components/ui/button';
import { useProcessing } from './contexts/ProcessingContext';
import { 
  AlertDialog,
  AlertDialogTrigger,
  AlertDialogContent,
  AlertDialogHeader,
  AlertDialogTitle,
  AlertDialogDescription,
  AlertDialogFooter
} from '@/components/ui/alert-dialog';

export default function HomePage() {
  const { state, updateState, resetState, setProcessingFile, startTimer, stopTimer, resetTimer } = useProcessing();
  const {
    selectedFile,
    currentAudioPath,
    isProcessing,
    isWhisperRunning,
    processResult,
    whisperOutput,
    recognitionElapsedTime,
    hasSrtFile,
    totalDuration,
    currentProgress,
    progressPercentage,
  } = state;
  
  const [isDragging, setIsDragging] = useState(false);
  const [settings, setSettings] = useState({
    whisper_models_path: null as string | null,
    whisper_language: 'auto' as string,
    whisper_model: 'ggml-large-v3.bin' as string,
  });
  const whisperOutputRef = useRef<HTMLDivElement>(null);
  const [stopDialogOpen, setStopDialogOpen] = useState(false);

  const handleFileSelect = (files: FileList | null) => {
    if (files && files.length > 0) {
      const file = files[0];
      const validTypes = ['video/', 'audio/'];
      if (validTypes.some(type => file.type.startsWith(type))) {
        setProcessingFile({
          name: file.name,
          size: file.size,
          type: file.type,
          path: null,
          blob: file,
        });
        updateState({ 
          processResult: null,
          whisperOutput: [],
          hasSrtFile: false,
          recognitionElapsedTime: 0
        }); // æ¸…é™¤ä¹‹å‰çš„å¤„ç†ç»“æœ
      } else {
        alert('è¯·é€‰æ‹©è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶');
      }
    }
  };

  // ä½¿ç”¨ Tauri å¯¹è¯æ¡†é€‰æ‹©åª’ä½“æ–‡ä»¶ï¼ˆè¿”å›æœ¬åœ°è·¯å¾„ï¼‰
  const pickMediaFileWithDialog = async () => {
    try {
      const pickedPath = await invoke('select_media_file');
      if (!pickedPath) return;

      // è·å–æ–‡ä»¶å…ƒä¿¡æ¯ï¼ˆåç§°/å¤§å°/ç±»å‹ï¼‰
      const info = await invoke('get_file_info', { path: pickedPath });
      const { name, size, kind } = info as { name: string; size: number; kind: string };

      setProcessingFile({
        name,
        size,
        type: kind,
        path: pickedPath as string,
        blob: null,
      });

      updateState({ 
        processResult: null,
        whisperOutput: [],
        hasSrtFile: false,
        recognitionElapsedTime: 0
      });
    } catch (e) {
      console.error('é€‰æ‹©æ–‡ä»¶å¤±è´¥:', e);
    }
  };

  const processMediaFile = async () => {
    if (!selectedFile) return;
    
    // æ£€æŸ¥Modelsè·¯å¾„æ˜¯å¦å·²é…ç½®
    if (!settings.whisper_models_path) {
      alert('è¯·å…ˆåœ¨è®¾ç½®é¡µé¢é…ç½® Whisper Models è·¯å¾„ï¼');
      return;
    }
    
    // æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    try {
      console.log('æ­£åœ¨æ£€æŸ¥æ¨¡å‹:', settings.whisper_model);
      const modelExists = await invoke('check_model_exists', {
        modelName: settings.whisper_model
      });
      
      console.log('æ¨¡å‹æ£€æŸ¥ç»“æœ:', modelExists);
      
      if (!modelExists) {
        alert(`âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${settings.whisper_model}\n\nğŸ“ è¯·ç¡®ä¿åœ¨ Models ç›®å½•ä¸­æœ‰å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶ï¼š\n${settings.whisper_models_path}/${settings.whisper_model}\n\nğŸ“¥ æ‚¨å¯ä»¥ä»ä»¥ä¸‹åœ°å€ä¸‹è½½æ¨¡å‹ï¼š\nâ€¢ https://huggingface.co/ggerganov/whisper.cpp/tree/main\nâ€¢ æˆ–ä½¿ç”¨ whisper.cpp çš„ download-ggml-model.sh è„šæœ¬\n\nğŸ’¡ ä¸‹è½½åè¯·å°†æ¨¡å‹æ–‡ä»¶æ”¾åœ¨é…ç½®çš„ Models ç›®å½•ä¸­`);
        return;
      }
      
      console.log('æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œç»§ç»­å¤„ç†...');
    } catch (error) {
      console.error('æ£€æŸ¥æ¨¡å‹å¤±è´¥:', error);
      const errorMessage = typeof error === 'string' ? error : String(error);
      
      if (errorMessage.includes('è¯·åœ¨è®¾ç½®ä¸­é…ç½®')) {
        alert('âŒ è¯·å…ˆåœ¨è®¾ç½®é¡µé¢é…ç½® Whisper Models è·¯å¾„ï¼');
      } else {
        alert(`âŒ æ£€æŸ¥æ¨¡å‹å¤±è´¥ï¼š${errorMessage}\n\nè¯·æ£€æŸ¥ï¼š\nâ€¢ Models è·¯å¾„æ˜¯å¦æ­£ç¡®é…ç½®\nâ€¢ æ˜¯å¦æœ‰è®¿é—®æƒé™`);
      }
      return;
    }
    
    updateState({
      isProcessing: true,
      processResult: null,
      whisperOutput: [],
      hasSrtFile: false,
    });
    
    try {
      let result: any;
      if (selectedFile.path) {
        // é€šè¿‡æœ¬åœ°è·¯å¾„å¤„ç†ï¼ˆæ— éœ€å‰ç«¯è¯»å–å­—èŠ‚ï¼‰
        result = await invoke('process_media_file_from_path', {
          inputPath: selectedFile.path,
        });
      } else if (selectedFile.blob) {
        // å›é€€åˆ°æµè§ˆå™¨æ–‡ä»¶å¯¹è±¡ï¼ˆæ‹–æ‹½ç­‰ï¼‰
        const fileBuffer = await selectedFile.blob.arrayBuffer();
        const fileData = Array.from(new Uint8Array(fileBuffer));
        result = await invoke('process_media_file', {
          fileData: fileData,
          fileName: selectedFile.name
        });
      } else {
        throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„æ–‡ä»¶æ¥æº');
      }
      
      console.log('FFmpeg å¤„ç†ç»“æœ:', result);
      updateState({ processResult: 'FFmpeg å¤„ç†æˆåŠŸï¼' });
      
      // è·å–éŸ³é¢‘æ–‡ä»¶è·¯å¾„å’Œè§†é¢‘æ—¶é•¿ï¼Œç„¶åå¯åŠ¨ whisper è¯†åˆ«
      const audioPath = (result as any).output_path;
      const duration = (result as any).duration_seconds;
      if (audioPath) {
        updateState({ 
          currentAudioPath: audioPath,
          totalDuration: duration
        });
        await startWhisperRecognition(audioPath, duration);
      }
    } catch (error) {
      console.error('å¤„ç†å¤±è´¥:', error);
      updateState({
        processResult: `å¤„ç†å¤±è´¥ï¼š${error}`,
        isProcessing: false,
      });
    }
  };

  const startWhisperRecognition = async (audioPath: string, duration?: number) => {
    try {
      // å¼€å§‹è®¡æ—¶
      startTimer();
      
      updateState({
        isWhisperRunning: true,
        processResult: 'æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...',
        currentProgress: 0,
        progressPercentage: 0,
      });
      
      await invoke('start_whisper_recognition', {
        audioFilePath: audioPath,
        totalDuration: duration || null
      });
    } catch (error) {
      console.error('Whisper è¯†åˆ«å¤±è´¥:', error);
      updateState({
        processResult: `Whisper è¯†åˆ«å¤±è´¥ï¼š${error}`,
        isWhisperRunning: false,
        isProcessing: false,
      });
      // åœæ­¢è®¡æ—¶å™¨ä½†ä¿ç•™æ—¶é—´æ˜¾ç¤º
      stopTimer();
    }
  };

  const stopWhisperRecognition = async () => {
    try {
      // åœæ­¢è®¡æ—¶å™¨ä½†ä¿ç•™æ—¶é—´æ˜¾ç¤º
      stopTimer();
      await invoke('stop_whisper_recognition');
    } catch (error) {
      console.error('åœæ­¢ Whisper å¤±è´¥:', error);
    }
  };

  const copyWhisperOutput = () => {
    const text = whisperOutput.join('\n');
    navigator.clipboard.writeText(text).then(() => {
      alert('å†…å®¹å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼');
    }).catch(err => {
      console.error('å¤åˆ¶å¤±è´¥:', err);
    });
  };
  
  // æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆç§’æ•°è½¬ä¸ºæ—¶:åˆ†:ç§’æ ¼å¼ï¼‰
  const formatTime = (seconds: number): string => {
    const hours = Math.floor(seconds / 3600);
    const minutes = Math.floor((seconds % 3600) / 60);
    const secs = Math.floor(seconds % 60);
    
    if (hours > 0) {
      return `${hours}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
    } else {
      return `${minutes}:${secs.toString().padStart(2, '0')}`;
    }
  };
  
  // æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ¯«ç§’è½¬ä¸ºæ—¶:åˆ†:ç§’.æ¯«ç§’æ ¼å¼ï¼‰
  const formatElapsedTime = (milliseconds: number): string => {
    const totalSeconds = Math.floor(milliseconds / 1000);
    const minutes = Math.floor(totalSeconds / 60);
    const seconds = totalSeconds % 60;
    const ms = Math.floor((milliseconds % 1000) / 10); // å–ååˆ†ä¹‹ä¸€ç§’
    
    if (minutes > 0) {
      return `${minutes}:${seconds.toString().padStart(2, '0')}.${ms.toString().padStart(2, '0')}`;
    } else {
      return `${seconds}.${ms.toString().padStart(2, '0')}ç§’`;
    }
  };
  
  // ä¿å­˜ SRT æ–‡ä»¶
  const saveSrtFile = async () => {
    if (!currentAudioPath) {
      alert('æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶è·¯å¾„');
      return;
    }
    
    try {
      // è®©ç”¨æˆ·é€‰æ‹©ä¿å­˜ç›®å½•
      const targetDirectory = await invoke('select_directory');
      if (!targetDirectory) {
        return; // ç”¨æˆ·å–æ¶ˆé€‰æ‹©
      }
      
      // ä¿å­˜ SRT æ–‡ä»¶
      const savedPath = await invoke('save_srt_file', {
        audioFilePath: currentAudioPath,
        targetDirectory: targetDirectory
      });
      
      alert(`SRT å­—å¹•æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š\n${savedPath}`);
    } catch (error) {
      console.error('ä¿å­˜ SRT æ–‡ä»¶å¤±è´¥:', error);
      alert(`ä¿å­˜ SRT æ–‡ä»¶å¤±è´¥ï¼š${error}`);
    }
  };
  
  // æ£€æŸ¥æ¨¡å‹çŠ¶æ€
  const checkModelStatus = async () => {
    if (!settings.whisper_models_path || !settings.whisper_model) {
      return;
    }
    
    try {
      const modelExists = await invoke('check_model_exists', {
        modelName: settings.whisper_model
      });
      if (!modelExists) {
        console.warn('æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨:', settings.whisper_model);
      }
    } catch (error) {
      console.error('æ£€æŸ¥æ¨¡å‹çŠ¶æ€å¤±è´¥:', error);
    }
  };

  // åŠ è½½è®¾ç½®
  const loadSettings = async () => {
    try {
      const result = await invoke('load_settings');
      setSettings(result as any);
    } catch (error) {
      console.error('åŠ è½½è®¾ç½®å¤±è´¥:', error);
    }
  };



  // ç»„ä»¶åŠ è½½æ—¶è‡ªåŠ¨åŠ è½½è®¾ç½®
  useEffect(() => {
    loadSettings();
  }, []);

  // å½“ whisper è¾“å‡ºæ›´æ–°æ—¶è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    if (whisperOutputRef.current) {
      whisperOutputRef.current.scrollTop = whisperOutputRef.current.scrollHeight;
    }
  }, [whisperOutput]);
  
  // å½“æ¨¡å‹æˆ–è·¯å¾„å‘ç”Ÿå˜åŒ–æ—¶æ£€æŸ¥æ¨¡å‹çŠ¶æ€
  useEffect(() => {
    checkModelStatus();
  }, [settings.whisper_model, settings.whisper_models_path]);

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
  };

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
    handleFileSelect(e.dataTransfer.files);
  };

  const formatFileSize = (bytes: number) => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  };

  const renderMainContent = () => {
    return (
      <div className="text-center max-w-4xl mx-auto">
        <div 
          className={`border-2 border-dashed rounded-xl p-16 my-10 transition-all duration-300 ease-in-out cursor-pointer min-h-[200px] flex flex-col items-center justify-center ${
            isDragging ? 'border-blue-500 bg-blue-50 dark:bg-blue-900/20 scale-105' : 
            selectedFile ? 'border-green-500 bg-green-50 dark:bg-green-900/20' : 
            'border-gray-300 dark:border-gray-600 bg-gray-50 dark:bg-gray-800'
          }`}
          onDragOver={handleDragOver}
          onDragLeave={handleDragLeave}
          onDrop={handleDrop}
        >
          {!selectedFile ? (
            <>
              <div className="text-6xl mb-5 opacity-60">ğŸ“</div>
              <p className="text-xl text-gray-600 dark:text-gray-300 mb-3 font-medium">
                å°†è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶æ‹–æ‹½åˆ°æ­¤å¤„
              </p>
              <p className="text-gray-500 dark:text-gray-400 mb-5">æˆ–è€…</p>
              <Button asChild>
                <span onClick={pickMediaFileWithDialog} className="cursor-pointer select-none">
                  é€‰æ‹©æ–‡ä»¶
                </span>
              </Button>
            </>
          ) : (
            <div className="flex items-center gap-5 text-left w-full max-w-xl">
              <div className="text-5xl flex-shrink-0">
                {selectedFile.type.startsWith('video/') ? 'ğŸ¬' : 'ğŸµ'}
              </div>
              <div className="flex-1">
                <h3 className="m-0 mb-2 text-gray-800 dark:text-gray-100 text-xl break-all">{selectedFile.name}</h3>
                <p className="my-1 text-gray-600 dark:text-gray-300 text-sm">å¤§å°: {formatFileSize(selectedFile.size)}</p>
                <p className="my-1 text-gray-600 dark:text-gray-300 text-sm">ç±»å‹: {selectedFile.type}</p>
                {selectedFile.path ? (
                  <p className="my-1 text-gray-600 dark:text-gray-300 text-sm break-all font-mono">
                    è·¯å¾„: {selectedFile.path}
                  </p>
                ) : null}
              </div>
              <div className="flex flex-col gap-3 flex-shrink-0">
                <Button 
                  onClick={processMediaFile}
                  disabled={isProcessing}
                  className="px-5 py-2.5"
                  variant={isProcessing ? "secondary" : "default"}
                >
                  {isProcessing ? (
                    isWhisperRunning ? 'è¯­éŸ³è¯†åˆ«ä¸­...' : 'å¤„ç†ä¸­...'
                  ) : 'å¼€å§‹å¤„ç†'}
                </Button>
                <Button 
                  variant="destructive"
                  size="sm"
                  onClick={() => {
                    resetTimer();
                    resetState();
                  }}
                  disabled={isProcessing}
                >
                  æ¸…é™¤æ–‡ä»¶
                </Button>
              </div>
            </div>
          )}
        </div>
        
        {processResult && (
          <div className={`my-5 p-4 rounded-lg font-medium text-center ${
            processResult.includes('æˆåŠŸ') ? 
            'bg-green-100 dark:bg-green-900/30 text-green-800 dark:text-green-200 border border-green-200 dark:border-green-700' : 
            'bg-red-100 dark:bg-red-900/30 text-red-800 dark:text-red-200 border border-red-200 dark:border-red-700'
          }`}>
            <div className="flex flex-col items-center gap-3">
              <div className="flex items-center justify-center gap-2">
                <span>{processResult}</span>
                {(isWhisperRunning && processResult.includes('è¯­éŸ³è¯†åˆ«')) || (processResult.includes('è¯­éŸ³è¯†åˆ«å®Œæˆ') && recognitionElapsedTime > 0) ? (
                  <span className="font-mono text-sm bg-blue-100 dark:bg-blue-900/50 px-2 py-1 rounded border">
                    â±ï¸ {formatElapsedTime(recognitionElapsedTime)}
                  </span>
                ) : null}
              </div>
              
              {/* è¿›åº¦æ¡ */}
              {isWhisperRunning && totalDuration && totalDuration > 0 && (
                <div className="w-full max-w-md">
                  <div className="flex justify-between text-xs text-gray-600 dark:text-gray-400 mb-1">
                    <span>{formatTime(currentProgress)}</span>
                    <span>{progressPercentage.toFixed(1)}%</span>
                    <span>{formatTime(totalDuration)}</span>
                  </div>
                  <div className="w-full bg-gray-200 dark:bg-gray-700 rounded-full h-2.5">
                    <div 
                      className="bg-blue-600 h-2.5 rounded-full transition-all duration-300 ease-out"
                      style={{ width: `${Math.min(progressPercentage, 100)}%` }}
                    ></div>
                  </div>
                </div>
              )}
            </div>
          </div>
        )}
        
        {(isWhisperRunning || whisperOutput.length > 0) && (
          <div className="my-8 border border-gray-200 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-800">
            <div className="flex justify-between items-center px-5 py-4 border-b border-gray-200 dark:border-gray-600 bg-white dark:bg-gray-700 rounded-t-lg">
              <h3 className="m-0 text-gray-800 dark:text-gray-100 text-lg">ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ</h3>
              <div className="flex gap-2">
                {isWhisperRunning && (
                  <AlertDialog open={stopDialogOpen} onOpenChange={setStopDialogOpen}>
                    <AlertDialogTrigger asChild>
                      <Button 
                        variant="destructive"
                        size="sm"
                      >
                        â¹ åœæ­¢
                      </Button>
                    </AlertDialogTrigger>
                    <AlertDialogContent>
                      <AlertDialogHeader>
                        <AlertDialogTitle>ç¡®è®¤åœæ­¢å½“å‰è¯†åˆ«ï¼Ÿ</AlertDialogTitle>
                        <AlertDialogDescription>
                          åœæ­¢åæœ¬æ¬¡è¯†åˆ«å°†è¢«ç»ˆæ­¢ä¸”æ— æ³•ç»§ç»­ã€‚
                        </AlertDialogDescription>
                      </AlertDialogHeader>
                      <AlertDialogFooter>
                        <Button 
                          variant="outline"
                          onClick={() => setStopDialogOpen(false)}
                        >
                          å–æ¶ˆ
                        </Button>
                        <Button 
                          variant="destructive"
                          onClick={async () => { await stopWhisperRecognition(); setStopDialogOpen(false); }}
                        >
                          ç¡®å®šåœæ­¢
                        </Button>
                      </AlertDialogFooter>
                    </AlertDialogContent>
                  </AlertDialog>
                )}
                {hasSrtFile && (
                  <Button 
                    variant="outline"
                    size="sm"
                    onClick={saveSrtFile}
                    disabled={isWhisperRunning}
                  >
                    ğŸ“ ä¿å­˜SRT
                  </Button>
                )}
                <Button 
                  variant="outline"
                  size="sm"
                  onClick={copyWhisperOutput}
                  disabled={isWhisperRunning || whisperOutput.length === 0}
                >
                  ğŸ“‹ å¤åˆ¶
                </Button>
              </div>
            </div>
            <div className="max-h-80 overflow-y-auto p-5 bg-gray-800 text-gray-200 font-mono text-sm leading-relaxed rounded-b-lg text-left whisper-output" ref={whisperOutputRef}>
              {whisperOutput.length === 0 ? (
                <div className="text-gray-400 italic text-left p-5">ç­‰å¾…è¾“å‡º...</div>
              ) : (
                whisperOutput.map((line, index) => (
                  <div key={index} className="mb-2 break-words">
                    {line}
                  </div>
                ))
              )}
              {isWhisperRunning && (
                <div className="whisper-cursor">â–®</div>
              )}
            </div>
          </div>
        )}
      </div>
    );
  };

  return renderMainContent();
}
